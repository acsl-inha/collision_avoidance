{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,itertools,argparse,os,time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "from typing import Type, Any, Callable, Union, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Train Implementation')\n",
    "parser.add_argument('--num_layers', nargs='+', type=int)\n",
    "parser.add_argument('--num_nodes', nargs='+', type=int)\n",
    "parser.add_argument('--index', type=int)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=np.load('mean.npy').tolist()\n",
    "std=np.load('std.npy').tolist()\n",
    "mean_test=np.load('mean_test.npy').tolist()\n",
    "std_test=np.load('std_test.npy').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,path):\n",
    "        xy = np.loadtxt(path,\n",
    "                        delimiter=',', dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = torch.tensor(xy[:, 0:5])\n",
    "        xy=xy.astype('int_')\n",
    "        self.y_data = torch.tensor(xy[:, 5])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=300\n",
    "lr=0.001\n",
    "\n",
    "num_layers=args.num_layers\n",
    "_nodes=args.num_nodes\n",
    "\n",
    "train_dataset = CustomDataset('norm_data_train_uniform_ext.csv')\n",
    "train_loader = DataLoader(dataset=train_dataset,pin_memory=True,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=60,drop_last=True)\n",
    "test_dataset = CustomDataset('norm_data_test_uniform_ext.csv')\n",
    "test_loader = DataLoader(dataset=test_dataset,pin_memory=True,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=60,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FClayer(nn.Module):\n",
    "    def __init__(self, innodes: int, nodes: int):\n",
    "        super(FClayer, self).__init__()\n",
    "        self.fc=nn.Linear(innodes,nodes)\n",
    "        self.act=nn.LeakyReLU(0.2, inplace=True)\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        out=self.fc(x)\n",
    "        out=self.act(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNET(nn.Module):\n",
    "    def __init__(self, block: Type[Union[FClayer]], planes: List[int], nodes: List[int], num_classes: int = 3\n",
    "                ) -> None:\n",
    "        super(WaveNET, self).__init__()\n",
    "        self.innodes=5\n",
    "        \n",
    "        self.layer1=self._make_layer(block, planes[0], nodes[0])\n",
    "        self.layer2=self._make_layer(block, planes[1], nodes[1])\n",
    "        self.layer3=self._make_layer(block, planes[2], nodes[2])\n",
    "        \n",
    "        self.fin_fc=nn.Linear(self.innodes,num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "    \n",
    "    def _make_layer(self, block: Type[Union[FClayer]], planes: int, nodes: int) -> nn.Sequential:\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.innodes, nodes))\n",
    "        self.innodes = nodes\n",
    "        for _ in range(1, planes):\n",
    "            layers.append(block(self.innodes, nodes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.fin_fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(block, planes, **kwargs):\n",
    "    model = WaveNET(block, planes, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.DataParallel(WaveNET(FClayer,num_layers,_nodes)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/16 15:42:17\n",
      "epoch: 1/120 | trn loss: 0.1490 | val loss: 0.0508 | val accuracy: 98.2211% \n",
      "\n",
      "2020/11/16 15:42:30\n",
      "epoch: 2/120 | trn loss: 0.0524 | val loss: 0.0433 | val accuracy: 98.5522% \n",
      "\n",
      "2020/11/16 15:42:43\n",
      "epoch: 3/120 | trn loss: 0.0480 | val loss: 0.0370 | val accuracy: 98.7922% \n",
      "\n",
      "2020/11/16 15:42:56\n",
      "epoch: 4/120 | trn loss: 0.0446 | val loss: 0.0463 | val accuracy: 98.5467% \n",
      "\n",
      "2020/11/16 15:43:07\n",
      "epoch: 5/120 | trn loss: 0.0425 | val loss: 0.0307 | val accuracy: 99.0656% \n",
      "\n",
      "2020/11/16 15:43:20\n",
      "epoch: 6/120 | trn loss: 0.0416 | val loss: 0.0486 | val accuracy: 98.3556% \n",
      "\n",
      "2020/11/16 15:43:33\n",
      "epoch: 7/120 | trn loss: 0.0393 | val loss: 0.0341 | val accuracy: 98.9000% \n",
      "\n",
      "2020/11/16 15:43:46\n",
      "epoch: 8/120 | trn loss: 0.0390 | val loss: 0.0289 | val accuracy: 99.1300% \n",
      "\n",
      "2020/11/16 15:43:58\n",
      "epoch: 9/120 | trn loss: 0.0381 | val loss: 0.0628 | val accuracy: 97.9811% \n",
      "\n",
      "2020/11/16 15:44:11\n",
      "epoch: 10/120 | trn loss: 0.0378 | val loss: 0.0385 | val accuracy: 98.6900% \n",
      "\n",
      "2020/11/16 15:44:24\n",
      "epoch: 11/120 | trn loss: 0.0355 | val loss: 0.0671 | val accuracy: 97.7644% \n",
      "\n",
      "2020/11/16 15:44:37\n",
      "epoch: 12/120 | trn loss: 0.0356 | val loss: 0.0404 | val accuracy: 98.6378% \n",
      "\n",
      "Model replaced and saved as  ./Custom_model_2.0_0.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type WaveNET. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type FClayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/16 15:44:50\n",
      "epoch: 13/120 | trn loss: 0.0343 | val loss: 0.0298 | val accuracy: 99.1322% \n",
      "\n",
      "Model replaced and saved as  ./Custom_model_2.0_0.030\n",
      "2020/11/16 15:45:03\n",
      "epoch: 14/120 | trn loss: 0.0351 | val loss: 0.0327 | val accuracy: 99.0256% \n",
      "\n",
      "2020/11/16 15:45:16\n",
      "epoch: 15/120 | trn loss: 0.0346 | val loss: 0.0476 | val accuracy: 98.2489% \n",
      "\n",
      "2020/11/16 15:45:29\n",
      "epoch: 16/120 | trn loss: 0.0339 | val loss: 0.0707 | val accuracy: 97.4256% \n",
      "\n",
      "2020/11/16 15:45:42\n",
      "epoch: 17/120 | trn loss: 0.0333 | val loss: 0.0382 | val accuracy: 98.7844% \n",
      "\n",
      "2020/11/16 15:45:55\n",
      "epoch: 18/120 | trn loss: 0.0331 | val loss: 0.0256 | val accuracy: 99.1922% \n",
      "\n",
      "Model replaced and saved as  ./Custom_model_2.0_0.026\n",
      "2020/11/16 15:46:09\n",
      "epoch: 19/120 | trn loss: 0.0329 | val loss: 0.0281 | val accuracy: 99.1400% \n",
      "\n",
      "2020/11/16 15:46:21\n",
      "epoch: 20/120 | trn loss: 0.0320 | val loss: 0.0282 | val accuracy: 99.1800% \n",
      "\n",
      "2020/11/16 15:46:35\n",
      "epoch: 21/120 | trn loss: 0.0309 | val loss: 0.0334 | val accuracy: 98.8267% \n",
      "\n",
      "2020/11/16 15:46:48\n",
      "epoch: 22/120 | trn loss: 0.0304 | val loss: 0.0303 | val accuracy: 99.0289% \n",
      "\n",
      "2020/11/16 15:47:01\n",
      "epoch: 23/120 | trn loss: 0.0296 | val loss: 0.0439 | val accuracy: 98.6933% \n",
      "\n",
      "2020/11/16 15:47:14\n",
      "epoch: 24/120 | trn loss: 0.0278 | val loss: 0.0205 | val accuracy: 99.3422% \n",
      "\n",
      "Model replaced and saved as  ./Custom_model_2.0_0.020\n",
      "2020/11/16 15:47:26\n",
      "epoch: 25/120 | trn loss: 0.0262 | val loss: 0.0212 | val accuracy: 99.2878% \n",
      "\n",
      "2020/11/16 15:47:39\n",
      "epoch: 26/120 | trn loss: 0.0248 | val loss: 0.0277 | val accuracy: 99.0556% \n",
      "\n",
      "2020/11/16 15:47:53\n",
      "epoch: 27/120 | trn loss: 0.0241 | val loss: 0.0328 | val accuracy: 98.6667% \n",
      "\n",
      "2020/11/16 15:48:06\n",
      "epoch: 28/120 | trn loss: 0.0236 | val loss: 0.0231 | val accuracy: 99.1489% \n",
      "\n",
      "2020/11/16 15:48:19\n",
      "epoch: 29/120 | trn loss: 0.0222 | val loss: 0.0260 | val accuracy: 99.0478% \n",
      "\n",
      "2020/11/16 15:48:32\n",
      "epoch: 30/120 | trn loss: 0.0227 | val loss: 0.0304 | val accuracy: 98.9511% \n",
      "\n",
      "2020/11/16 15:48:45\n",
      "epoch: 31/120 | trn loss: 0.0146 | val loss: 0.0234 | val accuracy: 99.2433% \n",
      "\n",
      "2020/11/16 15:48:58\n",
      "epoch: 32/120 | trn loss: 0.0135 | val loss: 0.0166 | val accuracy: 99.4044% \n",
      "\n",
      "Model replaced and saved as  ./Custom_model_2.0_0.017\n",
      "2020/11/16 15:49:11\n",
      "epoch: 33/120 | trn loss: 0.0131 | val loss: 0.0171 | val accuracy: 99.3689% \n",
      "\n",
      "2020/11/16 15:49:24\n",
      "epoch: 34/120 | trn loss: 0.0126 | val loss: 0.0308 | val accuracy: 99.0444% \n",
      "\n",
      "2020/11/16 15:49:36\n",
      "epoch: 35/120 | trn loss: 0.0125 | val loss: 0.0217 | val accuracy: 99.2767% \n",
      "\n",
      "2020/11/16 15:49:49\n",
      "epoch: 36/120 | trn loss: 0.0120 | val loss: 0.0240 | val accuracy: 99.2500% \n",
      "\n",
      "2020/11/16 15:50:03\n",
      "epoch: 37/120 | trn loss: 0.0119 | val loss: 0.0263 | val accuracy: 99.1533% \n",
      "\n",
      "2020/11/16 15:50:16\n",
      "epoch: 38/120 | trn loss: 0.0118 | val loss: 0.0243 | val accuracy: 99.2456% \n",
      "\n",
      "2020/11/16 15:50:29\n",
      "epoch: 39/120 | trn loss: 0.0119 | val loss: 0.0299 | val accuracy: 99.0233% \n",
      "\n",
      "2020/11/16 15:50:42\n",
      "epoch: 40/120 | trn loss: 0.0114 | val loss: 0.0303 | val accuracy: 99.0144% \n",
      "\n",
      "2020/11/16 15:50:55\n",
      "epoch: 41/120 | trn loss: 0.0115 | val loss: 0.0257 | val accuracy: 99.1222% \n",
      "\n",
      "2020/11/16 15:51:07\n",
      "epoch: 42/120 | trn loss: 0.0112 | val loss: 0.0398 | val accuracy: 98.5056% \n",
      "\n",
      "2020/11/16 15:51:19\n",
      "epoch: 43/120 | trn loss: 0.0113 | val loss: 0.0322 | val accuracy: 99.0278% \n",
      "\n",
      "2020/11/16 15:51:32\n",
      "epoch: 44/120 | trn loss: 0.0113 | val loss: 0.0395 | val accuracy: 98.5656% \n",
      "\n",
      "2020/11/16 15:51:45\n",
      "epoch: 45/120 | trn loss: 0.0112 | val loss: 0.0237 | val accuracy: 99.2467% \n",
      "\n",
      "2020/11/16 15:51:59\n",
      "epoch: 46/120 | trn loss: 0.0110 | val loss: 0.0189 | val accuracy: 99.3756% \n",
      "\n",
      "2020/11/16 15:52:12\n",
      "epoch: 47/120 | trn loss: 0.0111 | val loss: 0.0283 | val accuracy: 99.0744% \n",
      "\n",
      "2020/11/16 15:52:25\n",
      "epoch: 48/120 | trn loss: 0.0110 | val loss: 0.0215 | val accuracy: 99.2044% \n",
      "\n",
      "2020/11/16 15:52:37\n",
      "epoch: 49/120 | trn loss: 0.0109 | val loss: 0.0253 | val accuracy: 99.2267% \n",
      "\n",
      "2020/11/16 15:52:49\n",
      "epoch: 50/120 | trn loss: 0.0108 | val loss: 0.0254 | val accuracy: 99.1444% \n",
      "\n",
      "2020/11/16 15:53:01\n",
      "epoch: 51/120 | trn loss: 0.0107 | val loss: 0.0379 | val accuracy: 98.6600% \n",
      "\n",
      "2020/11/16 15:53:14\n",
      "epoch: 52/120 | trn loss: 0.0107 | val loss: 0.0254 | val accuracy: 99.1700% \n",
      "\n",
      "2020/11/16 15:53:26\n",
      "epoch: 53/120 | trn loss: 0.0107 | val loss: 0.0285 | val accuracy: 98.8756% \n",
      "\n",
      "2020/11/16 15:53:39\n",
      "epoch: 54/120 | trn loss: 0.0108 | val loss: 0.0389 | val accuracy: 98.6167% \n",
      "\n",
      "2020/11/16 15:53:51\n",
      "epoch: 55/120 | trn loss: 0.0106 | val loss: 0.0287 | val accuracy: 99.0289% \n",
      "\n",
      "2020/11/16 15:54:03\n",
      "epoch: 56/120 | trn loss: 0.0105 | val loss: 0.0302 | val accuracy: 98.9178% \n",
      "\n",
      "2020/11/16 15:54:16\n",
      "epoch: 57/120 | trn loss: 0.0105 | val loss: 0.0291 | val accuracy: 98.8778% \n",
      "\n",
      "2020/11/16 15:54:27\n",
      "epoch: 58/120 | trn loss: 0.0105 | val loss: 0.0233 | val accuracy: 99.2289% \n",
      "\n",
      "2020/11/16 15:54:42\n",
      "epoch: 59/120 | trn loss: 0.0103 | val loss: 0.0377 | val accuracy: 98.5922% \n",
      "\n",
      "2020/11/16 15:54:55\n",
      "epoch: 60/120 | trn loss: 0.0104 | val loss: 0.0279 | val accuracy: 98.9889% \n",
      "\n",
      "2020/11/16 15:55:08\n",
      "epoch: 61/120 | trn loss: 0.0093 | val loss: 0.0297 | val accuracy: 98.8444% \n",
      "\n",
      "2020/11/16 15:55:20\n",
      "epoch: 62/120 | trn loss: 0.0092 | val loss: 0.0292 | val accuracy: 98.9433% \n",
      "\n",
      "2020/11/16 15:55:33\n",
      "epoch: 63/120 | trn loss: 0.0092 | val loss: 0.0278 | val accuracy: 98.9867% \n",
      "\n",
      "2020/11/16 15:55:46\n",
      "epoch: 64/120 | trn loss: 0.0091 | val loss: 0.0310 | val accuracy: 98.8400% \n",
      "\n",
      "2020/11/16 15:55:58\n",
      "epoch: 65/120 | trn loss: 0.0091 | val loss: 0.0321 | val accuracy: 98.7933% \n",
      "\n",
      "2020/11/16 15:56:11\n",
      "epoch: 66/120 | trn loss: 0.0091 | val loss: 0.0290 | val accuracy: 98.8956% \n",
      "\n",
      "2020/11/16 15:56:24\n",
      "epoch: 67/120 | trn loss: 0.0091 | val loss: 0.0329 | val accuracy: 98.7711% \n",
      "\n",
      "2020/11/16 15:56:37\n",
      "epoch: 68/120 | trn loss: 0.0091 | val loss: 0.0293 | val accuracy: 98.8667% \n",
      "\n",
      "2020/11/16 15:56:50\n",
      "epoch: 69/120 | trn loss: 0.0091 | val loss: 0.0291 | val accuracy: 98.9011% \n",
      "\n",
      "2020/11/16 15:57:02\n",
      "epoch: 70/120 | trn loss: 0.0090 | val loss: 0.0268 | val accuracy: 99.0311% \n",
      "\n",
      "2020/11/16 15:57:16\n",
      "epoch: 71/120 | trn loss: 0.0090 | val loss: 0.0310 | val accuracy: 98.8744% \n",
      "\n",
      "2020/11/16 15:57:29\n",
      "epoch: 72/120 | trn loss: 0.0090 | val loss: 0.0297 | val accuracy: 98.8744% \n",
      "\n",
      "2020/11/16 15:57:42\n",
      "epoch: 73/120 | trn loss: 0.0090 | val loss: 0.0320 | val accuracy: 98.8044% \n",
      "\n",
      "2020/11/16 15:57:55\n",
      "epoch: 74/120 | trn loss: 0.0090 | val loss: 0.0311 | val accuracy: 98.8378% \n",
      "\n",
      "2020/11/16 15:58:08\n",
      "epoch: 75/120 | trn loss: 0.0090 | val loss: 0.0340 | val accuracy: 98.7289% \n",
      "\n",
      "2020/11/16 15:58:21\n",
      "epoch: 76/120 | trn loss: 0.0090 | val loss: 0.0346 | val accuracy: 98.7356% \n",
      "\n",
      "2020/11/16 15:58:33\n",
      "epoch: 77/120 | trn loss: 0.0089 | val loss: 0.0338 | val accuracy: 98.7778% \n",
      "\n",
      "2020/11/16 15:58:46\n",
      "epoch: 78/120 | trn loss: 0.0089 | val loss: 0.0305 | val accuracy: 98.8722% \n",
      "\n",
      "2020/11/16 15:58:59\n",
      "epoch: 79/120 | trn loss: 0.0089 | val loss: 0.0322 | val accuracy: 98.8078% \n",
      "\n",
      "2020/11/16 15:59:12\n",
      "epoch: 80/120 | trn loss: 0.0089 | val loss: 0.0334 | val accuracy: 98.7789% \n",
      "\n",
      "2020/11/16 15:59:25\n",
      "epoch: 81/120 | trn loss: 0.0089 | val loss: 0.0349 | val accuracy: 98.7467% \n",
      "\n",
      "2020/11/16 15:59:39\n",
      "epoch: 82/120 | trn loss: 0.0089 | val loss: 0.0327 | val accuracy: 98.8333% \n",
      "\n",
      "2020/11/16 15:59:50\n",
      "epoch: 83/120 | trn loss: 0.0089 | val loss: 0.0313 | val accuracy: 98.8522% \n",
      "\n",
      "2020/11/16 16:00:03\n",
      "epoch: 84/120 | trn loss: 0.0089 | val loss: 0.0289 | val accuracy: 98.9433% \n",
      "\n",
      "2020/11/16 16:00:16\n",
      "epoch: 85/120 | trn loss: 0.0089 | val loss: 0.0319 | val accuracy: 98.8322% \n",
      "\n",
      "2020/11/16 16:00:27\n",
      "epoch: 86/120 | trn loss: 0.0088 | val loss: 0.0308 | val accuracy: 98.8478% \n",
      "\n",
      "2020/11/16 16:00:40\n",
      "epoch: 87/120 | trn loss: 0.0088 | val loss: 0.0356 | val accuracy: 98.7189% \n",
      "\n",
      "2020/11/16 16:00:53\n",
      "epoch: 88/120 | trn loss: 0.0088 | val loss: 0.0293 | val accuracy: 98.9267% \n",
      "\n",
      "2020/11/16 16:01:06\n",
      "epoch: 89/120 | trn loss: 0.0088 | val loss: 0.0317 | val accuracy: 98.8344% \n",
      "\n",
      "2020/11/16 16:01:18\n",
      "epoch: 90/120 | trn loss: 0.0088 | val loss: 0.0340 | val accuracy: 98.7578% \n",
      "\n",
      "2020/11/16 16:01:30\n",
      "epoch: 91/120 | trn loss: 0.0087 | val loss: 0.0333 | val accuracy: 98.7867% \n",
      "\n",
      "2020/11/16 16:01:43\n",
      "epoch: 92/120 | trn loss: 0.0087 | val loss: 0.0320 | val accuracy: 98.8189% \n",
      "\n",
      "2020/11/16 16:01:55\n",
      "epoch: 93/120 | trn loss: 0.0087 | val loss: 0.0344 | val accuracy: 98.7533% \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/16 16:02:08\n",
      "epoch: 94/120 | trn loss: 0.0087 | val loss: 0.0323 | val accuracy: 98.8111% \n",
      "\n",
      "2020/11/16 16:02:21\n",
      "epoch: 95/120 | trn loss: 0.0087 | val loss: 0.0341 | val accuracy: 98.7622% \n",
      "\n",
      "2020/11/16 16:02:34\n",
      "epoch: 96/120 | trn loss: 0.0087 | val loss: 0.0346 | val accuracy: 98.7511% \n",
      "\n",
      "2020/11/16 16:02:47\n",
      "epoch: 97/120 | trn loss: 0.0087 | val loss: 0.0344 | val accuracy: 98.7600% \n",
      "\n",
      "2020/11/16 16:03:00\n",
      "epoch: 98/120 | trn loss: 0.0087 | val loss: 0.0331 | val accuracy: 98.7933% \n",
      "\n",
      "2020/11/16 16:03:13\n",
      "epoch: 99/120 | trn loss: 0.0087 | val loss: 0.0331 | val accuracy: 98.7911% \n",
      "\n",
      "2020/11/16 16:03:26\n",
      "epoch: 100/120 | trn loss: 0.0087 | val loss: 0.0338 | val accuracy: 98.7722% \n",
      "\n",
      "2020/11/16 16:03:39\n",
      "epoch: 101/120 | trn loss: 0.0087 | val loss: 0.0335 | val accuracy: 98.7811% \n",
      "\n",
      "2020/11/16 16:03:52\n",
      "epoch: 102/120 | trn loss: 0.0087 | val loss: 0.0324 | val accuracy: 98.8144% \n",
      "\n",
      "2020/11/16 16:04:05\n",
      "epoch: 103/120 | trn loss: 0.0087 | val loss: 0.0325 | val accuracy: 98.8067% \n",
      "\n",
      "2020/11/16 16:04:19\n",
      "epoch: 104/120 | trn loss: 0.0087 | val loss: 0.0328 | val accuracy: 98.7967% \n",
      "\n",
      "2020/11/16 16:04:32\n",
      "epoch: 105/120 | trn loss: 0.0086 | val loss: 0.0326 | val accuracy: 98.8033% \n",
      "\n",
      "2020/11/16 16:04:44\n",
      "epoch: 106/120 | trn loss: 0.0086 | val loss: 0.0334 | val accuracy: 98.7833% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "saving_path=\"./res_model\"\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "total_epoch=120\n",
    "model_char=\"_{}\".format(args.index)\n",
    "model_name=\"\"\n",
    "patience=10\n",
    "start_early_stop_check=0\n",
    "saving_start_epoch=10\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output= model(inputs)\n",
    "        # calculate loss\n",
    "        loss=criterion(output, labels)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del output\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        cor_match = 0\n",
    "        for j, val in enumerate(test_loader):\n",
    "            val_x, val_label = val\n",
    "            if torch.cuda.is_available():\n",
    "                val_x = val_x.cuda()\n",
    "                val_label =val_label.cuda()\n",
    "            val_output = model(val_x)\n",
    "            v_loss = criterion(val_output, val_label)\n",
    "            val_loss += v_loss\n",
    "            _, predicted=torch.max(val_output,1)\n",
    "            cor_match+=np.count_nonzero(predicted.cpu().detach()==val_label.cpu().detach())\n",
    "    del val_output\n",
    "    del v_loss\n",
    "    del predicted\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn_loss_list.append(trn_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss/len(test_loader))\n",
    "    val_acc=cor_match/(len(test_loader)*batch_size)\n",
    "    val_acc_list.append(val_acc)\n",
    "    now = time.localtime()\n",
    "    print (\"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec))\n",
    "\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | val accuracy: {:.4f}% \\n\".format(\n",
    "                epoch+1, total_epoch, trn_loss / len(train_loader), val_loss / len(test_loader), val_acc*100\n",
    "            ))\n",
    "    \n",
    "    \n",
    "    if epoch+1>2:\n",
    "        if val_loss_list[-1]>val_loss_list[-2]:\n",
    "            start_early_stop_check=1\n",
    "    else:\n",
    "        val_loss_min=val_loss_list[-1]\n",
    "        \n",
    "    if start_early_stop_check:\n",
    "        early_stop_temp=val_loss_list[-patience:]\n",
    "        if all(early_stop_temp[i]<early_stop_temp[i+1] for i in range (len(early_stop_temp)-1)):\n",
    "            print(\"Early stop!\")\n",
    "            break\n",
    "            \n",
    "    if epoch+1>saving_start_epoch:\n",
    "        if val_loss_list[-1]<val_loss_min:\n",
    "            if os.path.isfile(model_name):\n",
    "                os.remove(model_name)\n",
    "            val_loss_min=val_loss_list[-1]\n",
    "            model_name=saving_path+\"Custom_model_\"+model_char+\"_{:.3f}\".format(val_loss_min)\n",
    "            torch.save(model, model_name)\n",
    "            print(\"Model replaced and saved as \",model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setting\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Deg2Rad = np.pi/180\n",
    "Rad2Deg = 1/Deg2Rad\n",
    "\n",
    "dt = 0.1              # control frequency\n",
    "tf = 15               # final time\n",
    "g = 9.8\n",
    "K_alt = .8*2          # hdot loop gain    \n",
    "RoC = 20              # maximum rate of climb (max. of hdot)\n",
    "AoA0 = -1.71*Deg2Rad     # zero lift angle of attack\n",
    "Acc2AoA = 0.308333*Deg2Rad  # 1m/s^2 ACC corresponds to 0.308333deg AOA \n",
    "zeta_ap = 0.7         # pitch acceleration loop damping\n",
    "omega_ap = 4          # pitch acceleration loop bandwidth\n",
    "\n",
    "dist_sep = 100        # near mid-air collision range\n",
    "\n",
    "t = np.arange(0, tf, dt)\n",
    "N = len(t)\n",
    "# hdot loop dynamics definition\n",
    "\n",
    "def int_model(z, t, hdot_cmd):                          # computes state derivatives  \n",
    "    a, adot, h, hdot, R = z                           # state vector: a (pitch acc), adot, h (alt), hdot, R (ground-track range)\n",
    "    gamma=np.arcsin(hdot/Vm)                          # fight path angle\n",
    "    ac = K_alt * (hdot_cmd - hdot) + g/np.cos(gamma)  # pitch acceleration command\n",
    "    ac = np.clip(ac, -30, 30)                         # maneuver limit\n",
    "  \n",
    "    addot = omega_ap*omega_ap*(ac-a) - 2*zeta_ap*omega_ap*adot\n",
    "    hddot = a*np.cos(gamma) - g\n",
    "    Rdot = Vm*np.cos(gamma)\n",
    "    return np.array([adot, addot, hdot, hddot, Rdot]) # returns state derivatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player initial conditions\n",
    "total_sim=500\n",
    "\n",
    "hdot_flag=0\n",
    "res_Y = np.zeros(((N,7,total_sim)))                       # print-out data\n",
    "\n",
    "\n",
    "hdot_res_cmd=[]\n",
    "while True:\n",
    "    hdot_res=[]\n",
    "    hdot_res.append(0)\n",
    "    time_temp=0\n",
    "    errcmd=0\n",
    "    insight=0\n",
    "    \n",
    "    \n",
    "    hm0 = 1000                                                     # initial altitude\n",
    "    Vm = 200                                                       # initial speed\n",
    "    gamma0 = 0*Deg2Rad                                             # initial flight path angle\n",
    "    Pm_NED = np.array([0, 0, -hm0])                                # initial NED position\n",
    "    Vm_NED = np.array([Vm*np.cos(gamma0), 0, -Vm*np.sin(gamma0)])  # initial NED velocity\n",
    "\n",
    "    # state variable: [a, adot, h, hdot, R]\n",
    "    X0 = np.array([g/np.cos(gamma0), 0, hm0, -Vm_NED[2], 0])       # initial state vector\n",
    "\n",
    "    # target initial conditions\n",
    "    # randomly generated target initial conditions\n",
    "    #ht0 = 1000 + 200*np.random.randn()\n",
    "    ht0 = 1000 + 10+abs(50*np.random.randn())\n",
    "    #ht0 = 950\n",
    "    Vt = 200\n",
    "    approach_angle = 90*Deg2Rad*(2*np.random.rand()-1)\n",
    "    #approach_angle = np.pi/6\n",
    "    psi0 = np.pi + approach_angle + 2*np.random.randn()*Deg2Rad\n",
    "    #psi0 = np.pi*7/6\n",
    "    psi0 = np.arctan2(np.sin(psi0), np.cos(psi0))\n",
    "\n",
    "    Pt_N = 2000*(1+np.cos(approach_angle))\n",
    "    Pt_E = 2000*np.sin(approach_angle)\n",
    "    Pt_D = -ht0\n",
    "    Pt_NED = np.array([Pt_N, Pt_E, Pt_D])                             # initial NED position\n",
    "    Vt_NED = np.array([Vt*np.cos(psi0), Vt*np.sin(psi0), 0])       # initial NED velocity\n",
    "\n",
    "\n",
    "    # initialize variables\n",
    "    X = np.zeros((N,len(X0)))\n",
    "    X[0,:] = X0\n",
    "    dotX_p = 0\n",
    "\n",
    "    Y = np.zeros((N,7))                       # print-out data\n",
    "    theta0 = gamma0 + X0[0]*Acc2AoA + AoA0 # initial pitch angle\n",
    "\n",
    "    DCM = np.zeros((3,3))                      # initial DCM NED-to-Body\n",
    "    DCM[0,0] =  np.cos(theta0)\n",
    "    DCM[0,2] = -np.sin(theta0)\n",
    "    DCM[1,1] =  1\n",
    "    DCM[2,0] =  np.sin(theta0)\n",
    "    DCM[2,2] =  np.cos(theta0)\n",
    "\n",
    "    Pr_NED = Pt_NED - Pm_NED                   # relative NED position\n",
    "    Vr_NED = Vt_NED - Vm_NED                   # relative NED velosity\n",
    "\n",
    "    Pr_Body = np.dot(DCM, Pr_NED)              # relative position (Body frame)\n",
    "\n",
    "    # radar outputs\n",
    "    r = np.linalg.norm(Pr_Body)                # range\n",
    "    vc = -np.dot(Pr_NED, Vr_NED)/r             # closing velocity\n",
    "    elev = np.arctan2(Pr_Body[2], Pr_Body[0])  # target vertival look angle (down +)\n",
    "    azim = np.arctan2(Pr_Body[1], Pr_Body[0]/np.cos(theta0))  # target horizontal look angle (right +)\n",
    "\n",
    "    los = theta0 - elev                        # line of sight angle\n",
    "    dlos = 0\n",
    "    daz = 0\n",
    "\n",
    "    Y[0,:] = np.array([*Pm_NED, *Pt_NED,r]) \n",
    "    # static variables\n",
    "    los_p = los\n",
    "    dlos_p = dlos\n",
    "    azim_p = azim\n",
    "    daz_p = daz\n",
    "    cmd_hold = False\n",
    "    cmd_start = False\n",
    "    direction_avoid = 0\n",
    "    hdot_cmd = 0\n",
    "    hdot = 0\n",
    "    gamma = gamma0\n",
    "    count_change_hdot=0\n",
    "    count_change_hdot2=0\n",
    "    count_vert_col=0\n",
    "    err=0\n",
    "    vc0=vc\n",
    "\n",
    "    # main loop\n",
    "    for k in range(N-1):  \n",
    "        ##############################################################################\n",
    "        # UPDATE ENVIRONMENT AND GET OBSERVATION\n",
    "\n",
    "        # update environment\n",
    "        # adams-bashforth 2nd order integration\n",
    "        dotX = int_model(X[k,:], t[k], hdot_cmd)\n",
    "        X[k+1,:] = X[k,:] + 0.5*(3*dotX-dotX_p)*dt\n",
    "        dotX_p = dotX\n",
    "\n",
    "        Pt_NED = Pt_NED + Vt_NED*dt        # target position integration\n",
    "\n",
    "        # get observation\n",
    "\n",
    "        a, adot, h, hdot, R = X[k+1,:]\n",
    "\n",
    "        gamma = np.arcsin(hdot/Vm)\n",
    "        theta = gamma + a*Acc2AoA + AoA0\n",
    "\n",
    "        DCM = np.zeros((3,3))\n",
    "        DCM[0,0] =  np.cos(theta)\n",
    "        DCM[0,2] = -np.sin(theta)\n",
    "        DCM[1,1] =  1\n",
    "        DCM[2,0] =  np.sin(theta)\n",
    "        DCM[2,2] =  np.cos(theta)\n",
    "\n",
    "        Pm_NED = np.array([R, 0, -h]) \n",
    "        Vm_NED = np.array([Vm*np.cos(gamma), 0, -Vm*np.sin(gamma)])\n",
    "\n",
    "        Pr_NED = Pt_NED - Pm_NED\n",
    "        Vr_NED = Vt_NED - Vm_NED\n",
    "\n",
    "        Pr_Body = np.dot(DCM, Pr_NED)\n",
    "\n",
    "        r = np.linalg.norm(Pr_Body)\n",
    "        vc = -np.dot(Pr_NED, Vr_NED)/r \n",
    "        elev = np.arctan2(Pr_Body[2], Pr_Body[0])\n",
    "        azim = np.arctan2(Pr_Body[1], Pr_Body[0]/np.cos(theta))\n",
    "\n",
    "        psi = np.arctan2(Vt_NED[1], Vt_NED[0])\n",
    "\n",
    "        # los rate and az rate estimation\n",
    "        los = theta - elev\n",
    "\n",
    "        dlos = ( 30*(los-los_p) + 0*dlos_p ) / 3 # filtered LOS rate, F(s)=20s/(s+20)\n",
    "        daz = ( 30*(azim-azim_p) + 0*daz_p ) / 3 # filtered azim rate, F(s)=20s/(s+20)\n",
    "\n",
    "        los_p = los\n",
    "        dlos_p = dlos\n",
    "        azim_p = azim\n",
    "        daz_p = daz\n",
    "\n",
    "        # estimate closest approach\n",
    "        min_dist_vert = r*r/vc*dlos\n",
    "        min_dist_horiz = r*r/vc0*daz\n",
    "\n",
    "        # estimate cruise distance\n",
    "        dist_cruise = r*los\n",
    "\n",
    "        ##############################################################################\n",
    "        # COMPUTE ACTION (BEGIN)\n",
    "        if k>3 and r>dist_sep and abs(elev)<40*Deg2Rad and abs(azim)<40*Deg2Rad:\n",
    "            insight+=1\n",
    "            data=torch.tensor(((np.array([r,vc,los,daz,dlos])\n",
    "                 -mean)/std).astype(np.float32)).cuda()\n",
    "            output=model(data)\n",
    "            _, predicted=torch.max(output,1)\n",
    "            if predicted[0]==0:\n",
    "                hdot_cmd=0\n",
    "            if predicted[0]==1:\n",
    "                if hdot_cmd!=-20:\n",
    "                    count_change_hdot+=1\n",
    "                hdot_cmd=-20\n",
    "            if predicted[0]==2:\n",
    "                if hdot_cmd!=20:\n",
    "                    count_change_hdot+=1\n",
    "                hdot_cmd=20\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        ##############################################################################\n",
    "        # WRITE DATA\n",
    "        elif k>3:\n",
    "            hdot_cmd=0\n",
    "        Y[k+1,:] = np.array([*Pm_NED, *Pt_NED,r]) \n",
    "    if insight>0:\n",
    "        hdot_res_cmd.append(count_change_hdot)\n",
    "        res_Y[:,:,hdot_flag]=Y\n",
    "        hdot_flag+=1\n",
    "        if hdot_flag%100==0:\n",
    "            print(hdot_flag)\n",
    "    if hdot_flag==total_sim:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=0\n",
    "disy=np.zeros(total_sim)\n",
    "for i in range (total_sim):\n",
    "    disy[i]=min(res_Y[:,6,i])\n",
    "    if min(res_Y[:,6,i])<dist_sep:\n",
    "        err+=1\n",
    "print(\"error with test down sim {}: \".format(total_sim), err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
