각 에피소드 시뮬레이션 종료 조건을 완화하여 시뮬레이션을 길게 만든 결과, 지금까지중 그나마 가장 의도한 결과가 도출되었다. 그러나 이 방법대로는 역시 수렴이 어려울것 같아 알고리즘 자체를 수정할 필요가 있어 보인다.
따라서 Rainbow DQN을 사용하여 다시 학습 시켜보려 한다.
