{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import gym\n",
    "import gym_Aircraft\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import Categorical\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common import make_vec_env\n",
    "envs = make_vec_env('acav-v0', n_envs=16)\n",
    "env = gym.make('acav-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        action_probs    = self.actor(x)\n",
    "        dist  = Categorical(action_probs)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = env.observation_space.shape[0]\n",
    "num_outputs = env.action_space.n\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 256\n",
    "lr               = 3e-4\n",
    "num_steps        = 100\n",
    "mini_batch_size  = 5\n",
    "ppo_epochs       = 4\n",
    "threshold_reward = 1\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 10000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    total_res=[]\n",
    "    res_list=np.zeros(11)\n",
    "    entropy = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample().view(-1,1)\n",
    "        next_state, reward, done, info = envs.step(action.cpu().numpy())\n",
    "        \n",
    "        # save data to print\n",
    "        cmd_list,r_list,elev_list,azim_list,Pm_list,Pt_list,h_list=info[0][\"info\"]\n",
    "        Pm_list=Pm_list.tolist()\n",
    "        Pt_list=Pt_list.tolist()\n",
    "        merged_data=itertools.chain([cmd_list],[r_list],[elev_list],[azim_list],Pm_list,Pt_list,[h_list])\n",
    "        merged_data=np.array(list(merged_data))\n",
    "        res_list=np.vstack([res_list,merged_data])\n",
    "        \n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env() for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "                \n",
    "    res_list=np.delete(res_list,0,0)      \n",
    "    total_res.append(res_list)\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach().view(-1,1)\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions).view(-1,1)\n",
    "    advantage = returns - values\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info[0][\"info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deg2Rad = np.pi/180\n",
    "Rad2Deg = 1/Deg2Rad\n",
    "\n",
    "plt_res=total_res[-1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,9), dpi=100)\n",
    "\n",
    "plt.subplot(511)\n",
    "plt.plot(plt_res[:,0], label=r'$\\dot{h}_{cmd}$')\n",
    "plt.ylabel(r'$\\dot{h}_{cmd}$ ($m/s$)'), plt.grid()\n",
    "\n",
    "plt.subplot(512)\n",
    "plt.plot(plt_res[:,10],label=r'$\\{h}$')\n",
    "plt.ylabel(r'$h$ (m)'), plt.grid()\n",
    "\n",
    "plt.subplot(513)\n",
    "plt.plot(plt_res[:,1],label=r'$\\{r}$')\n",
    "plt.ylabel(r'$r$ (m)'), plt.grid()\n",
    "\n",
    "plt.subplot(514)\n",
    "plt.plot(plt_res[:,2]*Rad2Deg, label='elevation')\n",
    "plt.ylabel('elevation (deg)'), plt.grid()\n",
    "\n",
    "plt.subplot(515)\n",
    "plt.plot(plt_res[:,3]*Rad2Deg, label='azimuth')\n",
    "plt.ylabel('azimuth (deg)'), plt.grid()\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectory plots\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.figure(figsize=(12,9), dpi=100)\n",
    "plt.gca(projection='3d')\n",
    "plt.plot(plt_res[:,5], plt_res[:,4], -plt_res[:,6], label='player', linewidth=3)\n",
    "plt.plot(plt_res[:,8], plt_res[:,7], -plt_res[:,9], label='target', linewidth=3)\n",
    "plt.xlabel('East')\n",
    "plt.ylabel('North')\n",
    "plt.xlim(-2000,2000)\n",
    "plt.ylim(0,4000)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,9), dpi=100)\n",
    "plt.plot(plt_res[:,5], plt_res[:,4], label='player', linewidth=3)\n",
    "plt.plot(plt_res[:,8], plt_res[:,7], label='target', linewidth=3)\n",
    "plt.xlabel('East')\n",
    "plt.ylabel('North')\n",
    "plt.grid(), plt.legend(), plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,9), dpi=100)\n",
    "plt.plot(plt_res[:,4], -plt_res[:,6], label='player', linewidth=3)\n",
    "plt.plot(plt_res[:,7], -plt_res[:,9], label='target', linewidth=3)\n",
    "plt.xlabel('North')\n",
    "plt.ylabel('Up')\n",
    "plt.grid(), plt.legend(), plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
